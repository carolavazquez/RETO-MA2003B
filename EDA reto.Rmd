---
title: "EDA Reto"
output:
  html_document:
    df_print: paged
date: "2025-08-22"
---

```{r}
library(readxl)
library(dplyr)
library(janitor)
library(lubridate)

path <- file.choose()  # abre el explorador de archivos


# Ver hojas disponibles (por si necesitas elegir)
excel_sheets(path)

# Leer la primera hoja (o pon el nombre exacto de la hoja)
df <- read_excel(
  path,
  sheet = 1,                           # o "2023", "2024", etc.
  na = c("", "NA", "-99", "-999", "-9999"),
  guess_max = 100000                   # mejora la detecci√≥n de tipos en archivos grandes
) |>
  clean_names()
```
```{r}
# valores √∫nicos de la primera fila
vals <- as.character(unlist(df[1, ], use.names = FALSE))
vals <- trimws(vals)

unicos <- sort(unique(vals[!is.na(vals) & vals != ""]))
cat(paste(unicos, collapse = "\n"))

```
```{r}
library(dplyr)
library(tidyr)
library(stringr)
library(lubridate)
library(janitor)

# contaminantes v√°lidos
CONT_OK <- c("CO","NO","NO2","NOX","O3","PM10","PM2.5","PRS","RAINF","RH","SO2","SR","TOUT","WDR","WDV","WSR")

date_col <- intersect(c("date"), names(df))
stopifnot(length(date_col) >= 1)
date_col <- date_col[1]

# diccionario col -> contaminante leyendo la PRIMERA fila
lab_primera <- toupper(trimws(as.character(df[1, ])))
dicc <- tibble(col = names(df), etiqueta = lab_primera) |>
  filter(etiqueta %in% CONT_OK)

# columnas de estaci√≥n (todas menos la fecha)
cols_est <- setdiff(dicc$col, date_col)

# quito la fila 1 que tra√≠a etiquetas, y me quedo con fecha + estaciones
dat <- df[-1, c(date_col, cols_est)]

# normalizo la fecha (varios formatos posibles; tambi√©n n√∫meros de Excel)
parse_dt <- function(x){
  if (is.numeric(x)) return(as.POSIXct(as.numeric(x)*86400, origin="1899-12-30", tz="America/Monterrey"))
  x <- as.character(x)
  out <- suppressWarnings(ymd_hms(x, tz="America/Monterrey"))
  out[is.na(out)] <- suppressWarnings(ymd_hm(x, tz="America/Monterrey"))[is.na(out)]
  out[is.na(out)] <- suppressWarnings(ymd(x, tz="America/Monterrey"))[is.na(out)]
  out
}
dat[[date_col]] <- parse_dt(dat[[date_col]])

# paso a largo, asigno estaci√≥n y contaminante por columna
df_long <- dat |>
  pivot_longer(-all_of(date_col), names_to = "col", values_to = "valor_raw") |>
  mutate(
    contaminante = dicc$etiqueta[match(col, dicc$col)],
    col_norm = tolower(col) |> str_replace_all("\\s+", "_"),
    estacion = toupper(str_remove(col_norm, "_\\d+$")),
    valor = suppressWarnings(as.numeric(valor_raw))
  ) |>
  select(date = all_of(date_col), estacion, contaminante, valor)

# resumen r√°pido
cat("Observaciones:", nrow(df_long),
    "| Contaminantes:", n_distinct(df_long$contaminante), "\n")

```
```{r}
eda <- df_long |>
  group_by(estacion, contaminante) |>
  mutate(
    med = median(valor, na.rm = TRUE),
    mad1 = mad(valor, constant = 1.4826, na.rm = TRUE),
    zrob = (valor - med)/mad1,
    outlier = !is.na(zrob) & abs(zrob) > 3
  ) |>
  ungroup()

# tabla de outliers por contaminante y por estaci√≥n
out_por_cont <- eda |> summarise(n = n(), outs = sum(outlier, na.rm=TRUE),
                                 pct = 100*outs/n, .by = contaminante) |>
  arrange(desc(pct))
out_por_est  <- eda |> summarise(n = n(), outs = sum(outlier, na.rm=TRUE),
                                 pct = 100*outs/n, .by = estacion) |>
  arrange(desc(pct))

print(out_por_cont)
print(head(out_por_est, 20))

```
### Qu√© muestra esta tabla
Es un resumen de outliers por contaminante. Para cada contaminante reporto:

n: cu√°ntas observaciones hay.

outs: cu√°ntas quedaron marcadas como at√≠picas con el criterio |z-score robusto| > 3 (calculado por estaci√≥n‚Äìcontaminante usando mediana y MAD).

pct: el porcentaje de outliers respecto a n.

### C√≥mo interpretar los porcentajes

SR aprox 39%. SR (radiaci√≥n solar) tiene distribuci√≥n ‚Äúmixta‚Äù: de noche aprox 0 y de d√≠a sube mucho. Si mezclo d√≠a+noche en el mismo umbral, la MAD queda peque√±a (muchos ceros) y los valores diurnos ‚Äúsaltan‚Äù como at√≠picos. No es que 39% est√© mal: hay que evaluar SR separando d√≠a/noche (o por hora).

WDR/WDV aprox 12‚Äì13%. Son direcciones de viento (variables angulares). Un z-score lineal no aplica (0¬∞ y 360¬∞ son el mismo punto). Se deben tratar como √°ngulos o convertir el viento a componentes u = WSR¬∑cos(Œ∏) y v = WSR¬∑sin(Œ∏) y evaluar ah√≠ los outliers.

NO, NOX, SO2 aprox 7‚Äì17%. Gases con picos de episodio (tr√°fico, estabilidad). Es normal ver colas pesadas y porcentajes m√°s altos que en una normal ideal.

PM10 / PM2.5 / O3 aprox 2‚Äì5%. Rango esperado; indica menos extremos (o que ya se suavizan al promediar).


```{r}
library(dplyr)
library(tidyr)

# d√≥nde hay duplicados
dups <- df_long |>
  summarise(n = dplyr::n(), .by = c(date, estacion, contaminante)) |>
  filter(n > 1L)

# colapso duplicados: promedio por (date, estacion, contaminante)
df_long_dedup <- df_long |>
  mutate(valor = suppressWarnings(as.numeric(valor))) |>
  summarise(valor = mean(valor, na.rm = TRUE),
            .by = c(date, estacion, contaminante))

```

```{r}

wind_uv <- df_long_dedup |>
  filter(contaminante %in% c("WDV","WSR")) |>
  # paso a ancho ya sin duplicados
  pivot_wider(names_from = contaminante, values_from = valor) |>
  # coerci√≥n segura + normalizaci√≥n angular
  mutate(
    WDV = suppressWarnings(as.numeric(WDV)),
    WSR = suppressWarnings(as.numeric(WSR)),
    WDV = (WDV %% 360)
  ) |>
  mutate(
    u = WSR * cos(pi * WDV / 180),
    v = WSR * sin(pi * WDV / 180)
  ) |>
  select(date, estacion, u, v)

# lo regreso a largo para juntarlo con el resto
wind_uv_long <- wind_uv |>
  pivot_longer(c(u, v), names_to = "contaminante", values_to = "valor")

```

```{r}
# base para outliers: todo menos WDR/WDV; en su lugar uso u/v
base_out <- df_long_dedup |>
  filter(!contaminante %in% c("WDR","WDV")) |>
  bind_rows(wind_uv_long)

# z-score robusto por estaci√≥n‚Äìcontaminante;
# para SR separo d√≠a/noche para no inflar outliers
library(lubridate)

df_tag <- base_out |>
  mutate(hora = hour(date),
         grupo = ifelse(contaminante == "SR" & hora %in% 6:18, "SR_DIA",
                 ifelse(contaminante == "SR", "SR_NOCHE", "REG"))) |>
  group_by(estacion, contaminante, grupo) |>
  mutate(
    med  = median(valor, na.rm = TRUE),
    mad1 = mad(valor, constant = 1.4826, na.rm = TRUE),
    zrob = (valor - med)/mad1,
    outlier = is.finite(zrob) & abs(zrob) > 3
  ) |>
  ungroup()

resumen_out <- df_tag |>
  filter(!contaminante %in% c("u","v")) |>
  summarise(n = dplyr::n(),
            outs = sum(outlier, na.rm = TRUE),
            pct = 100*outs/n,
            .by = contaminante) |>
  arrange(desc(pct))

print(resumen_out)

```

Viento en componentes. Las direcciones WDR/WDV son angulares (0¬∞ ‚â° 360¬∞), as√≠ que un z-score lineal no es v√°lido. Convert√≠ el viento a u = WSR¬∑cos(Œ∏) y v = WSR¬∑sin(Œ∏) (con Œ∏ en grados, WSR en m/s) y us√© u/v para el etiquetado de outliers. Tambi√©n forc√© WDV/WSR a num√©rico y normalic√© WDV a [0,360).

SR por d√≠a y noche. La radiaci√≥n solar (SR) es ~0 de noche y alta de d√≠a. Si mezclo ambos, la MAD queda peque√±a y ‚Äútodo el d√≠a‚Äù parece at√≠pico. Por eso separ√© SR en dos grupos (d√≠a 06‚Äì18 h y noche) y a cada grupo le apliqu√© su propio umbral.

Criterio robusto y por estaci√≥n. Marqu√© outliers con ‚à£ùëßrob‚à£>3, dondeùëßrob=(ùë•‚àímediana)/MAD, calculado por estaci√≥n y contaminante (y por franja en SR). No elimin√© datos; solo los etiquet√©.


Resultado despu√©s de las correcciones (aprox.)

SR ~ 23.7% (baj√≥ desde ~39% al separar d√≠a/noche).

NO ~ 16.9%, NOX ~ 10.3%, SO2 ~ 7.5%, NO2 ~ 5.4%: gases con picos de episodio; es esperable ver colas pesadas.

PM10 ~ 4.3%, PM2.5 ~ 2.9%, O3 ~ 2.3%, CO ~ 1.7%, PRS ~ 1.4%: rangos razonables para este m√©todo.

El n de PM2.5 es menor porque no todas las estaciones reportan esa variable en todo el periodo.



### C√≥mo usarlo en el an√°lisis

Mantengo los valores originales y la bandera de outlier para hacer an√°lisis con y sin outliers (sensibilidad).

Para comparar estaciones (topograf√≠a), trabajaremos con promedios diarios por estaci√≥n y contaminante, exigiendo cobertura ‚â• 75% de horas por d√≠a.

En multivariado (PCA/MANOVA por estaci√≥n) usar√© contaminantes en escala z y, para viento, u/v en vez de √°ngulos crudos.

Esta estrategia evita falsos positivos por estructura del dato (√°ngulos, d√≠a/noche) y deja los outliers como se√±al f√≠sica real cuando corresponde (episodios).

```{r}
library(readr)
# Discretizaci√≥n con intenci√≥n: episodios p90 por contaminante
episodios <- df_long_dedup |>
  summarise(thres_p90 = quantile(valor, 0.90, na.rm = TRUE),
            .by = contaminante)

freq_episodios <- df_long_dedup |>
  left_join(episodios, by = "contaminante") |>
  mutate(ep90 = valor >= thres_p90) |>
  summarise(pct_episodios = mean(ep90, na.rm = TRUE) * 100,
            .by = c(estacion, contaminante)) |>
  arrange(contaminante, desc(pct_episodios))

# Agregados diarios con cobertura ‚â• 75% y escalado z para multivariado
diario <- df_long_dedup |>
  mutate(fecha = as.Date(date)) |>
  summarise(
    n_ok  = sum(!is.na(valor)),
    media = if_else(n_ok >= 18, mean(valor, na.rm = TRUE), NA_real_),
    .by = c(estacion, fecha, contaminante)
  )

X_day <- diario |>
  select(estacion, fecha, contaminante, media) |>
  pivot_wider(names_from = contaminante, values_from = media)

cont_cols <- intersect(c("CO","NO","NO2","NOX","O3","PM10","PM2.5","SO2"),
                       names(X_day))

X_day_z <- X_day |>
  mutate(across(all_of(cont_cols), ~ as.numeric(scale(.x)),
                .names = "{.col}_z"))

# Atributos derivados √∫tiles (lluvia diaria y % horas en calma)
rain_day <- df_long_dedup |>
  filter(contaminante == "RAINF") |>
  mutate(fecha = as.Date(date)) |>
  summarise(rain_mm = sum(as.numeric(valor), na.rm = TRUE),
            .by = c(estacion, fecha))

calma_day <- df_long_dedup |>
  filter(contaminante == "WSR") |>
  mutate(WSR = as.numeric(valor), fecha = as.Date(date)) |>
  summarise(pct_calma = mean(WSR < 1, na.rm = TRUE) * 100,
            .by = c(estacion, fecha))

X_features <- X_day |>
  left_join(rain_day, by = c("estacion","fecha")) |>
  left_join(calma_day, by = c("estacion","fecha"))

# 4) Reformateos finales y guardados
df_horario         <- df_long_dedup
df_diario_ancho    <- X_day
df_diario_features <- X_features |>
  mutate(across(all_of(cont_cols), ~ as.numeric(scale(.x)),
                .names = "{.col}_z"))

write_csv(df_horario,         "aire_mty_horario_long_dedup.csv")
write_csv(df_diario_ancho,    "aire_mty_diario_ancho.csv")
write_csv(df_diario_features, "aire_mty_diario_features.csv")
write_csv(freq_episodios,     "aire_mty_freq_episodios_p90.csv")

# chequeos r√°pidos para el informe
cat("Estaciones:", n_distinct(df_long_dedup$estacion),
    "| Contaminantes:", n_distinct(df_long_dedup$contaminante),
    "| Obs horarias:", nrow(df_long_dedup), "\n")

faltantes <- df_diario_ancho |>
  summarise(across(-c(estacion, fecha), ~ mean(is.na(.))*100))
print(faltantes)
```
```{r}
dplyr::glimpse(df_horario)
dplyr::count(df_horario, estacion, contaminante) |> head()
names(df_diario_ancho) 
head(freq_episodios)

```
### Formato de la base y qu√© verifiqu√©
Dejamos la base en formato largo con cuatro columnas: date (hora), estaci√≥n, contaminante y valor. El dataset resultante tiene 2,964,339 filas, y la lista de contaminantes es la esperada (CO, NO, NO‚ÇÇ, NOx, O‚ÇÉ, PM10, PM2.5, PRS, RAINF, RH, SO‚ÇÇ, SR, TOUT, WSR, WDV/WDR). Con esto confirmo que el reetiquetado y la reestructuraci√≥n quedaron correctos para an√°lisis por estaci√≥n y por contaminante.

### Cobertura por estaci√≥n‚Äìcontaminante
Antes de comparar estaciones, revisamos la cobertura (n√∫mero de horas con dato por estaci√≥n y contaminante). Por ejemplo, en CENTRO obtuvimos alrededor de 13,293 registros por contaminante; esa magnitud de n nos indica que hay informaci√≥n suficiente para calcular promedios diarios y comparar estaciones con un criterio homog√©neo. Esta verificaci√≥n es importante porque, si una estaci√≥n tuviera muy pocas horas v√°lidas, su comparaci√≥n podr√≠a sesgarse.

### Frecuencia de episodios altos (p90)
Para medir ‚Äúacumulamiento‚Äù desde otra perspectiva, calculamos la frecuencia de episodios: porcentaje de horas que est√°n por arriba del percentil 90 (p90) global de cada contaminante. En CO, el ranking muestra a NORESTE ‚âà 35.3% y NORESTE2 ‚âà 27.7% como las estaciones con mayor proporci√≥n de horas altas, seguidas por SUROESTE2 (~14.9%), CENTRO (~13.5%), SURESTE (~12.3%) y NOROESTE_2 (~10.2%). Esta se√±al es consistente con acumulamiento local (topograf√≠a + configuraci√≥n de fuentes) en el eje noreste: no es un pico aislado, sino una frecuencia sostenida de valores altos. Este mismo an√°lisis lo aplicaremos a NO/NO‚ÇÇ/NOx y PM2.5/PM10; si las mismas estaciones aparecen arriba en varios contaminantes, la evidencia de efecto topogr√°fico se fortalece. Para O‚ÇÉ, anticipo patrones distintos por su formaci√≥n secundaria.

### C√≥mo usamos esta informaci√≥n en el an√°lisis
Con la base larga y la cobertura revisada, construimos promedios diarios por estaci√≥n‚Äìcontaminante (exigiendo ‚â•75% de horas por d√≠a) y trabajo en dos planos:

- Comparaci√≥n univariada por contaminante (ANOVA/Kruskal) para detectar diferencias sistem√°ticas entre estaciones.

- Enfoque multivariado (PCA/MANOVA) con contaminantes estandarizados para ver si las estaciones forman clusters coherentes.
En paralelo, reportamos la frecuencia de episodios p90 por estaci√≥n como indicador complementario de acumulamiento. Esta combinaci√≥n nos da una lectura robusta y alineada con el objetivo: evaluar si la topograf√≠a de Monterrey se asocia con diferencias persistentes en los niveles de contaminantes entre estaciones.

